{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BE - Visualizing and validating data\n",
    "\n",
    "Dwayne Herzberg\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mzipfile\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mio\u001b[39;00m \u001b[39mimport\u001b[39;00m StringIO\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import zipfile\n",
    "from io import StringIO\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_PATH = pathlib.Path().resolve()\n",
    "DATA_DIRECTORY = NOTEBOOK_PATH / \"data\"\n",
    "\n",
    "FILE_NAME = \"BrtPdm_CHIMIE_20230221.zip\"\n",
    "\n",
    "COLUMNS_TIME = [\n",
    "    \"20t_Date\",\n",
    "    \"20t_DateZero\",\n",
    "    \"20t_DateMaz\"\n",
    "]\n",
    "\n",
    "TIME_FORMAT = \"%d/%m/%Y,%H:%M:%S\"\n",
    "\n",
    "COLUMN_TYPES = {\n",
    "    \"5d_CO\": int,\n",
    "    \"5d_COvrai\": int,\n",
    "    \"8s_flag\": \"string\",\n",
    "    \"6.4f_ratio\": float,\n",
    "    \"6.0f_agci\": float,\n",
    "    \"5.1f_intT\": float,\n",
    "    \"5.2f_flow\": float,\n",
    "    \"5d_bkg\": int,\n",
    "    \"5.2f_coef\": float,\n",
    "    \"6.1f_biasvoltage\": float,\n",
    "    \"5d_moy\": int,\n",
    "    \"5.1f_ect\": float,\n",
    "    \"5d_vMin\": int,\n",
    "    \"5d_vMax\": int,\n",
    "    \"5d_oldBkg\": int,\n",
    "    \"5d_newBkg\": int,\n",
    "    \"4d_Ozone\": int,\n",
    "    \"4d_Pression\": int,\n",
    "    \"4.2f_flowA\": float,\n",
    "    \"4.2f_flowB\": float,\n",
    "    \"3.1f_bkg\": float,\n",
    "    \"5.1f_benchT\": float,\n",
    "    \"5.1f_O3lampT\": float,\n",
    "    \"5.1f_lampSetting\": float,\n",
    "    \"6d_cellAInt\": int,\n",
    "    \"6d_cellBInt\": int,\n",
    "}\n",
    "\n",
    "# can be useful\n",
    "COLUMNS_DESCRIPTIVE = {\n",
    "    \"5d_CO\": \"\",\n",
    "    \"5d_COvrai\": \"\",\n",
    "    \"6.4f_ratio\": \"\",\n",
    "    \"6.0f_agci\": \"\",\n",
    "    \"5.1f_intT\": \"\",\n",
    "    \"5.2f_flow\": \"\",\n",
    "    \"5d_bkg\": \"\",\n",
    "    \"5.2f_coef\": \"\",\n",
    "    \"6.1f_biasvoltage\": \"\",\n",
    "    \"5d_moy\": \"\",\n",
    "    \"5.1f_ect\": \"\",\n",
    "    \"5d_vMin\": \"\",\n",
    "    \"5d_vMax\": \"\",\n",
    "    \"5d_oldBkg\": \"\",\n",
    "    \"5d_newBkg\": \"\",\n",
    "    # TEI49 - Ozone\n",
    "    \"8s_flag\": \"status code\",\n",
    "    \"4d_Ozone\": \"ozone concentration\",\n",
    "    \"4d_Pression\": \"pressure measurements\",\n",
    "    \"4.2f_flowA\": \"flow rates channel A\",\n",
    "    \"4.2f_flowB\": \"flow rates channel B\",\n",
    "    \"3.1f_bkg\": \"background signal\",\n",
    "    \"5.1f_benchT\": \"instrument's bench temperature\",\n",
    "    \"5.1f_O3lampT\": \"ozone lamp temperature\",\n",
    "    \"5.1f_lampSetting\": \"ozone lamp setting\",\n",
    "    \"6d_cellAInt\": \"cell A intensity\",\n",
    "    \"6d_cellBInt\": \"cell B intensity\",\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_zip_file(zip_file_path: str) -> dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read the contents of a zip file and return a dictionary of DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    zip_file_path : str\n",
    "        The path to the zip file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames with the file name as the key.\n",
    "    \"\"\"\n",
    "    dfs: dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    with zipfile.ZipFile(zip_file_path, \"r\") as zip_ref:\n",
    "        for file_name in zip_ref.namelist():\n",
    "            if file_name.endswith(\".txt\"):\n",
    "                with zip_ref.open(file_name) as file:\n",
    "                    file_contents = file.read().decode(\"utf-8\")\n",
    "                try:\n",
    "                    header, data = file_contents.strip().split(\"\\n\", 1)\n",
    "                    header_list = header.split(sep=\",\")\n",
    "                    df = pd.read_csv(StringIO(data), header=None,\n",
    "                                     names=header_list, sep=\" \")\n",
    "                except ValueError:\n",
    "                    header_list = file_contents.strip().split(sep=\",\")\n",
    "                    df = pd.DataFrame(columns=header_list)\n",
    "                file_name = file_name.replace(\".txt\", \"\")\n",
    "                df.Name = file_name\n",
    "                dfs[file_name] = df\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = read_zip_file(\"BrtPdm_Chimie_20190817.zip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def for_each_df(dfs: dict[str, pd.DataFrame], func: callable, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    Apply a function to each DataFrame in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "\n",
    "    func : callable\n",
    "        A function to apply to each DataFrame.\n",
    "\n",
    "    **kwargs\n",
    "        Keyword arguments to pass to the function.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If dfs is not a dictionary of DataFrames.\n",
    "    TypeError\n",
    "        If dfs keys are not strings.\n",
    "    TypeError\n",
    "        If dfs values are not DataFrames.\n",
    "    TypeError\n",
    "        If func is not a callable.\n",
    "    \"\"\"\n",
    "    if not isinstance(dfs, dict):\n",
    "        raise TypeError(\"dfs must be a dictionary of DataFrames\")\n",
    "\n",
    "    if not all(isinstance(key, str) for key in dfs.keys()):\n",
    "        raise TypeError(\"dfs keys must be strings\")\n",
    "\n",
    "    if not all(isinstance(df, pd.DataFrame) for df in dfs.values()):\n",
    "        raise TypeError(\"dfs values must be DataFrames\")\n",
    "\n",
    "    if not callable(func):\n",
    "        raise TypeError(\"func must be a callable\")\n",
    "\n",
    "    for df in dfs.values():\n",
    "        func(df, **kwargs)\n",
    "\n",
    "\n",
    "def apply_time_df(df: pd.DataFrame, time_columns: list[str], time_format: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Convert columns in a DataFrame to datetime64.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to convert the columns in.\n",
    "\n",
    "    time_columns : list[str]\n",
    "        A list of column names to convert to datetime64.\n",
    "\n",
    "    time_format : str | None\n",
    "        The format of the time columns. If None, the default format is used.\n",
    "    \"\"\"\n",
    "    for col in time_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df[col] = pd.to_datetime(df[col], format=time_format)\n",
    "            except ValueError as e:\n",
    "                print(\n",
    "                    f\"Failed to convert column {col} to datetime64 on {df.Name}.\")\n",
    "                print(e)\n",
    "\n",
    "\n",
    "def apply_time_dfs(dfs: dict[str, pd.DataFrame], time_columns: list[str], time_format: str | None = None) -> None:\n",
    "    \"\"\"\n",
    "    Convert columns in a dictionary of DataFrames to datetime64.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        The dictionary of DataFrames to convert the columns in.\n",
    "\n",
    "    time_columns : list[str]\n",
    "        A list of column names to convert to datetime64.\n",
    "\n",
    "    time_format : str | None\n",
    "        The format of the time columns. If None, the default format is used.\n",
    "    \"\"\"\n",
    "    for_each_df(dfs, apply_time_df, time_columns=time_columns,\n",
    "                time_format=time_format)\n",
    "\n",
    "\n",
    "def apply_types_df(df: pd.DataFrame, dtype_dict: dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Apply specified data types to columns in a DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to apply the data types to.\n",
    "\n",
    "    dtype_dict : dict[str, str]\n",
    "        A dictionary of column names and data types.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the data types applied.\n",
    "    \"\"\"\n",
    "    for column, dtype in dtype_dict.items():\n",
    "        if column in df.columns:\n",
    "            df[column] = df[column].astype(dtype)\n",
    "\n",
    "\n",
    "def apply_types_dfs(dfs: dict[str, pd.DataFrame], dtype_dict: dict[str, str]) -> None:\n",
    "    \"\"\"\n",
    "    Apply specified data types to columns in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "\n",
    "    dtype_dict : dict[str, str]\n",
    "        A dictionary of column names and data types.\n",
    "    \"\"\"\n",
    "    for_each_df(dfs, apply_types_df, dtype_dict=dtype_dict)\n",
    "\n",
    "\n",
    "def check_dtype_df(df: pd.DataFrame, dtype_dict: dict[str, str], time_columns: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Check that the data types of a DataFrame are correct.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to check.\n",
    "\n",
    "    dtype_dict : dict[str, str]\n",
    "        A dictionary of column names and data types.\n",
    "\n",
    "    time_columns : list[str]\n",
    "        A list of columns that should be datetime objects.\n",
    "    \"\"\"\n",
    "    for column, dtype in dtype_dict.items():\n",
    "        if column not in df.columns:\n",
    "            continue\n",
    "        if df[column].dtype != dtype:\n",
    "            print(\n",
    "                f\"Column {column} should be {dtype}, not '{df[column].dtype}' on {df.Name}\")\n",
    "\n",
    "    for column in time_columns:\n",
    "        if column not in df.columns:\n",
    "            continue\n",
    "        if df[column].dtype != \"datetime64[ns]\":\n",
    "            print(\n",
    "                f\"Column {column} should be datetime64[ns], not '{df[column].dtype}' on {df.Name}\")\n",
    "\n",
    "\n",
    "def check_dtype_dfs(dfs: dict[str, pd.DataFrame], dtype_dict: dict[str, str], time_columns: list[str]) -> None:\n",
    "    \"\"\"\n",
    "    Check that the data types of a dictionary of DataFrames are correct.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "\n",
    "    dtype_dict : dict[str, str]\n",
    "        A dictionary of column names and data types.\n",
    "\n",
    "    time_columns : list[str]\n",
    "        A list of columns that should be datetime objects.\n",
    "    \"\"\"\n",
    "    for_each_df(dfs, check_dtype_df, dtype_dict=dtype_dict,\n",
    "                time_columns=time_columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "configuring the columns types:\n",
    "  - `date` columns are converted to `datetime` objects (COLUMNS_TIME)\n",
    "  - each column is converted to the appropriate type (COLUMN_TYPES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_types_dfs(dfs, COLUMN_TYPES)\n",
    "apply_time_dfs(dfs, COLUMNS_TIME, TIME_FORMAT)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each column on each dataframe, check if all types are respected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_dtype_dfs(dfs, COLUMN_TYPES, COLUMNS_TIME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(dfs: dict[str, pd.DataFrame], name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Get a DataFrame from a dictionary of DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "\n",
    "    name : str\n",
    "        The name of the DataFrame to get.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        The DataFrame with the specified name.\n",
    "    \"\"\"\n",
    "    if name not in dfs.keys():\n",
    "        raise KeyError(f\"DataFrame {name} not found in dictionary\")\n",
    "    return dfs[name]\n",
    "\n",
    "\n",
    "def print_shape_df(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Print the number of rows and columns in a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to print the shape of.\n",
    "    \"\"\"\n",
    "    print(f\"{df.Name} has {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "\n",
    "def print_shape_dfs(dfs: dict[str, pd.DataFrame]) -> None:\n",
    "    \"\"\"\n",
    "    Print the number of rows and columns in a dictionary of DataFrames.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    for_each_df(dfs, print_shape_df)\n",
    "\n",
    "\n",
    "def print_df_names(dfs: dict[str, pd.DataFrame]) -> None:\n",
    "    \"\"\"\n",
    "    Print the names of the DataFrames in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "    \"\"\"\n",
    "    for name in dfs.keys():\n",
    "        print(name)\n",
    "\n",
    "\n",
    "def get_df_names(dfs: dict[str, pd.DataFrame]) -> list[str]:\n",
    "    \"\"\"\n",
    "    Get the names of the DataFrames in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dfs : dict[str, pd.DataFrame]\n",
    "        A dictionary of DataFrames.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        A list of the names of the DataFrames in the dictionary.\n",
    "    \"\"\"\n",
    "    return list(dfs.keys())\n",
    "\n",
    "\n",
    "def get_column_descriptions(column: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the description of a column from the COLUMNS_DESCRIPTIVE dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    column : str\n",
    "        The name of the column to get the description of.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The description of the column.\n",
    "    \"\"\"\n",
    "    if column in COLUMNS_DESCRIPTIVE.keys():\n",
    "        return COLUMNS_DESCRIPTIVE[column]\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def analyse_time_column(df: pd.DataFrame, column: str) -> None:\n",
    "    \"\"\"\n",
    "    Print information about a time column in a DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to analyse.\n",
    "\n",
    "    column : str\n",
    "        The name of the column to analyse.\n",
    "    \"\"\"\n",
    "    print(f\"{df.Name} - {column}\")\n",
    "    print(f\"First: {df[column].min()}\")\n",
    "    print(f\"Last: {df[column].max()}\")\n",
    "\n",
    "\n",
    "def plot_df(df: pd.DataFrame, columns_ref: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot each column in a DataFrame on a separate plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        The DataFrame to plot.\n",
    "\n",
    "    columns_ref : str\n",
    "        The name of the column to use as the reference for the x-axis.\n",
    "    \"\"\"\n",
    "    df.plot(subplots=True, x=columns_ref, figsize=(15, 10))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "files are grouped by instrument:\n",
    "- Files named `TEI48` are linked to an instrument from **CO**.\n",
    "- Files named `TEI49` are linked to an instrument from **Ozone**.\n",
    "\n",
    "files are grouped by type:\n",
    "- `Data` files are the **data**\n",
    "- The `Fonct` files are the **operating parameters** of the instruments\n",
    "- The `Zero` file is related to a **calibration** of the CO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_df_names(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_shape_dfs(dfs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEI49 - Ozone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- both files\n",
    "  - **20t_Date**: Date and time of each measurement. The \"20t\" indicates that the timestamp includes 20 characters.\n",
    "- Data file\n",
    "  - **4d_Ozone**: Ozone concentration measurements, in units of parts per billion (ppb). The \"4d\" indicates that the variable is represented with 4 decimal places of precision.\n",
    "  - **4d_Pression**: Pressure measurements, in units of millibars (mb). The \"4d\" indicates that the variable is represented with 4 decimal places of precision.\n",
    "- Fonct file\n",
    "  - **8s_flag**: Flag or status code for each measurement. The \"8s\" indicates that the variable is represented with 8 characters.\n",
    "  - **4.2f_flowA** and **4.2f_flowB**: Flow rates of the two channels in the instrument. The \"4.2f\" indicates that the variables are represented with 4 digits before the decimal point and 2 digits after the decimal point.\n",
    "  - **3.1f_bkg**: Background signal in the instrument. The \"3.1f\" indicates that the variable is represented with 3 digits before the decimal point and 1 digit after the decimal point.\n",
    "  - **5.2f_coef**: Calibration coefficient for the instrument. The \"5.2f\" indicates that the variable is represented with 5 digits before the decimal point and 2 digits after the decimal point.\n",
    "  - **5.1f_benchT**, **5.1f_O3lampT**, **5.1f_intT**, and **5.1f_lampSetting**: temperature of the instrument's bench, the temperature of the ozone lamp, the internal temperature of the instrument, and the setting of the ozone lamp. The \"5.1f\" indicates that the variables are represented with 5 digits before the decimal point and 1 digit after the decimal point.\n",
    "  - **6d_cellAInt** and **6d_cellBInt**: Intensities of the two channels in the instrument. The \"6d\" likely indicates that the variables are represented with 6 digits."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEI49_Data = get_df(dfs, \"Pdm_TEI49_Data_20230221\")\n",
    "TEI49_Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_time_column(TEI49_Data, \"20t_Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEI49_Data.describe().loc[[\"min\", \"max\", \"mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(TEI49_Data, \"20t_Date\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonct file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEI49_Fonct = get_df(dfs, \"Pdm_TEI49_Fonct_20230221\")\n",
    "TEI49_Fonct.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse_time_column(TEI49_Fonct, \"20t_Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEI49_Fonct.describe().loc[[\"min\", \"max\", \"mean\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df(TEI49_Fonct, \"20t_Date\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "be_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c56fc54a269accdd2369d30a627d9cd4a367f1675927dc962925265e3798f1cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
